<div class="post-block"><link itemprop="mainEntityOfPage" href="http://lonepatient.top/2018/03/03/Deep_Learning_For_Computer_Vision_With_Python_PB_04.html"><span hidden="" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><meta itemprop="name" content="eamlife"><meta itemprop="description" content=""><meta itemprop="image" content="/images/touxiang.jpeg"></span><span hidden="" itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization"><meta itemprop="name" content="eamlife's blog"></span><header class="post-header"><h2 class="post-title" itemprop="name headline">深度学习与计算机视觉(PB-04)-rank-N准确度</h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-03-03T07:27:08+08:00">2018-03-02 </time></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/深度学习/" itemprop="url" rel="index"><span itemprop="name">深度学习</span> </a></span>， <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/深度学习/计算机视觉/" itemprop="url" rel="index"><span itemprop="name">计算机视觉</span> </a></span></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2018/03/03/Deep_Learning_For_Computer_Vision_With_Python_PB_04.html#comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/2018/03/03/Deep_Learning_For_Computer_Vision_With_Python_PB_04.html" itemprop="commentCount">0</span> </a></span><span id="/2018/03/03/Deep_Learning_For_Computer_Vision_With_Python_PB_04.html" class="leancloud_visitors" data-flag-title="深度学习与计算机视觉(PB-04)-rank-N准确度"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数:</span> <span class="leancloud-visitors-count">1</span></span><div class="post-wordcount"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">字数统计:</span> <span title="字数统计">2.2k 字</span></div></div></header><div id="copyBtn" style="opacity: 0; position: absolute;top:0px;display: none;line-height: 1; font-size:1.5em"><span id="imgCopy"><i class="fa fa-paste fa-fw"></i></span><span id="imgSuccess" style="display: none;"><i class="fa fa-check-circle fa-fw" aria-hidden="true"></i></span></div><div class="post-body" itemprop="articleBody"><p>在我们深入讨论高级深度学习主题(如迁移学习)之前，先来了解下rank-1、rank-5和rank-N准确度的概念。当你在阅读深度学习相关文献时，尤其是关于计算机视觉和图像分类，你很可能会看到关于rank-N 准确度。例如，几乎所有在ImageNet数据集上验证的机器学习方法的论文都给出了rank-1和rank-5准确度 (我们将在本章后面解释为什么需要使用rank-1和rank-5准确度).</p><a id="more"></a><p>rank-N准确度指标与传统的评估指标有何不同呢？在本节中，我们将讨论rank-N准确度内容以及如何实现它。最后将其应用于在Flower-17和CALTECH-101数据集上。</p><h2 id="rank-N准确度"><a href="#rank-N准确度" class="headerlink" title="rank-N准确度"></a>rank-N准确度</h2><p>通过一个例子来解释rank-N准确度概念。假设我们正在评估一个训练在CIFAR-10数据集上的神经网络模型，CIFAR-10数据集包括10个类:飞机，汽车，鸟、猫、鹿、狗、青蛙、马、船和卡车。给定一张输入图像(如图4.1左)</p><p><a href="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/91735389.jpg" class="fancybox fancybox.image" rel="group"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/91735389.jpg" alt=""></a></p><center>图4.1 左：青蛙， 右：汽车</center><p>模型返回的结果是表4.1左的类标签概率信息。<br><a href="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/24826590.jpg" class="fancybox fancybox.image" rel="group"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/24826590.jpg" alt=""></a></p><center>表4.1 左：图4.1左图预测结果， 右：图4.1右图预测结果</center><p>我们先看看rank-1的计算，对于每一张图片，取模型预测的类概率列表中最大的概率对应的标签作为该图片的预测结果。比如，我们使用图4.1左对应真实标签为青蛙的图片进行预测，得到表4.1左结果，从中可以看到最大概率为97.3%对应的预测结果也为青蛙，说明预测结果是对的。因此，可以看到计算rank-1的整个过程为:</p><ul><li>步骤1：计算数据集中每个输入图像的类标签概率。</li><li>步骤2：原始标签与对应概率最大的标签进行比较，若相同为true，反之false</li><li>步骤3：统计步骤2为true的个数</li></ul><p>上面我们计算的是rank-1准确度，即对应预测最高概率的标签与真实标签相同的个数占总个数的百分比——标签相同的个数 / 总数据个数。</p><p>现在，我们扩展到rank-5准确度，我们关注的不是top1的预测，而是top5的预测，那么整个计算过程如下:</p><ul><li>步骤1： 计算数据集中每个输入图像的类标签概率。</li><li>步骤2： 对预测的类标签概率进行降序排序</li><li>步骤3： 判断真实的标签是否落在预测的top5标签里面，若存在，则标记为true，反之false</li><li>步骤4： 统计步骤3中为true的个数</li></ul><p>rank-5准确度是rank-1准确度的扩展，我们对一张图片的预测结果是来自模型输出结果中top5对应的5个预测，而不是top1的1个预测。例如，我们对图4.1右图片进行预测，rank-5对应的预测结果为表4.1右结果。</p><p>很显然图4.1右是一辆汽车，然而，如果使用的是rank-1预测的话，结果为卡车，显然是不对的。但是如果使用rank-5的话，发现汽车实际上是第2个预测结果，这时候对于rank-5预测而言是正确的。这种方法也可以很容易地推广到计算rank-N准确度。 一般而言，我们只计算rank-1和rank-5准确度——计算rank-1的准确度可以理解，为什么还需要计算rank-5准确度呢？</p><p>对于CIFAR-10数据集来说，由于本身类别个数不多，计算rank-5准确度有点不太合适。但对于大型的、具有挑战性的数据集来说，特别是细粒度的分类。从Szegedy[17]等人的论文中的一个例子或许可以很好的解释为什么需要计算rank-1和rank-5准确度。比如图4.2中，我们可以看到左边是西伯利亚哈士奇，右边是爱斯基摩犬。从人的肉眼来看是无法区分开的，但是这个在ImageNet 数据集中是有效的标签。</p><p><a href="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/64462328.jpg" class="fancybox fancybox.image" rel="group"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/64462328.jpg" alt=""></a></p><center>图4.2，左：西伯利亚哈士奇，右： 爱斯基摩犬</center><p>当处理的大型数据集各个类别之间存在许多具有相似特征时，我们往往会增加一个rank-5准确度，也就是说我们不止关心rank-1准确度，也关心rank-5准确度。结合两个准确度来以衡量神经网络的性能。理想情况下，随着预测数据增加，希望rank-1准确度和rank-5准确度同比例增加。但是，在某些数据集上，情况往往并非总是如此。</p><p>因此，我们也根据rank-5准确度检验模型，以确保我们的网络在后面的迭代中仍然是“学习”的。在训练快结束时，rank-1准确度可能会停滞不前，但是当我们的网络学习到更多的识别特征(虽然没有足够的识别能力超过top1的预测)时，rank-5准确度会继续提高。</p><h2 id="实现rank-1和rank-5准确度"><a href="#实现rank-1和rank-5准确度" class="headerlink" title="实现rank-1和rank-5准确度"></a>实现rank-1和rank-5准确度</h2><p>我们可以通过在项目中构建一个工具模块来计算rank-1和rank-5准确度。因此，在pyimagesearch<br>项目中增加一个子模块utils，并在子模块中增加一个ranked.py脚本，整个目录结构如下:<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line">--- pyimagesearch</span><br><span class="line">|    |--- __init__.py</span><br><span class="line">|    |--- callbacks</span><br><span class="line">|    |--- io</span><br><span class="line">|    |--- nn</span><br><span class="line">|    |--- preprocessing</span><br><span class="line">|    |--- utils</span><br><span class="line">|        |--- __init__.py</span><br><span class="line">|        |--- captchahelper.py</span><br><span class="line">|        |--- ranked.py</span><br></pre></td></tr></tbody></table></figure></div><p></p><p>打开ranked.py脚本，写入以下代码：<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line"><span class="comment">#encoding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rank5_accuracy</span><span class="params">(preds,labels)</span>:</span></span><br><span class="line">    <span class="comment">#初始化</span></span><br><span class="line">    rank1 = <span class="number">0</span></span><br><span class="line">    rank5 = <span class="number">0</span></span><br></pre></td></tr></tbody></table></figure></div><p></p><p>定义了rank5_accuracy函数，主要需要传入两个参数:</p><ul><li>preds: 一个NxT的矩阵，其中N表示行数，T表示列数，每个值代表对应标签下的概率</li><li>labels： 原始数据中的真实标签</li></ul><p>接下来计算rank-1和rank-5:<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line"><span class="comment"># 遍历数据集</span></span><br><span class="line"><span class="keyword">for</span> (p,gt) <span class="keyword">in</span> zip(preds,labels):</span><br><span class="line">    <span class="comment"># 通过降序对概率进行排序</span></span><br><span class="line">    p = np.argsort(p)[::<span class="number">-1</span>]</span><br><span class="line">    <span class="comment"># 检查真实标签是否落在top5中</span></span><br><span class="line">    <span class="keyword">if</span> gt <span class="keyword">in</span> p[:<span class="number">5</span>]:</span><br><span class="line">        rank5 += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 检验真实标签是否等于top1</span></span><br><span class="line">    <span class="keyword">if</span> gt == p[<span class="number">0</span>]:</span><br><span class="line">        rank1 += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 计算准确度</span></span><br><span class="line">rank1 /= float(len(labels))</span><br><span class="line">rank5 /= float(len(labels))</span><br><span class="line"><span class="keyword">return</span> rank1,rank5</span><br></pre></td></tr></tbody></table></figure></div><p></p><h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><p><a href="">第2节</a>中，我们使用了预先训练好的VGG16模型对三种数据集提取了特征，并对特征向量训练了逻辑回归模型，以及对模型进行了评估，接下来，我们将使用rank-1和rank-5准确度进行型评估。</p><p>新建一个脚本文件，名为rank_accuracy.py，并写入以下代码：<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line"><span class="comment">#encoding:utf-8</span></span><br><span class="line"><span class="keyword">from</span> pyimagesearch.utils.ranked <span class="keyword">import</span> rank5_accuracy</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> h5py</span><br></pre></td></tr></tbody></table></figure></div><p></p><p>接下来，解析命令行参数:<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line"><span class="comment"># 解析命令行参数</span></span><br><span class="line">ap = argparse.ArgumentParser()</span><br><span class="line">ap.add_argument(<span class="string">'-d'</span>,<span class="string">'--db'</span>,required=<span class="keyword">True</span>,help=<span class="string">'path HDF5 databases'</span>)</span><br><span class="line">ap.add_argument(<span class="string">'-m'</span>,<span class="string">'--model'</span>,required=<span class="keyword">True</span>,help = <span class="string">'path to pre-trained model'</span>)</span><br><span class="line">args = vars(ap.parse_args())</span><br></pre></td></tr></tbody></table></figure></div><p></p><p>主要有两个参数：</p><ul><li>—db: HDF5数据路径</li><li>—model：之前训练好的logistic regression模型路径</li></ul><p>由于我们使用的是前75%的数据进行训练，因此，我们使用后25%数据进行预测和评估：<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line"><span class="comment"># 加载模型</span></span><br><span class="line">print(<span class="string">"[INFO] loading pre-trained model..."</span>)</span><br><span class="line">model = pickle.loads(open(args[<span class="string">'model'</span>],<span class="string">'rb'</span>).read())</span><br><span class="line"></span><br><span class="line">db = h5py.File(args[<span class="string">'db'</span>],<span class="string">'r'</span>)</span><br><span class="line">i = int(db[<span class="string">'labels'</span>].shape[<span class="number">0</span>] * <span class="number">0.75</span>)</span><br><span class="line"><span class="comment"># 预测</span></span><br><span class="line"><span class="keyword">print</span> (<span class="string">"[INFO] predicting...."</span>)</span><br><span class="line">preds = model.predict_proba(db[<span class="string">'features'</span>][i:])</span><br><span class="line">(rank1,rank5) = rank5_accuracy(preds,db[<span class="string">'labels'</span>][i:])</span><br><span class="line"><span class="comment"># 结果打印</span></span><br><span class="line">print(<span class="string">"[INFO] rank-1:{:.2f}%"</span>.format(rank1 * <span class="number">100</span>))</span><br><span class="line">print(<span class="string">"[INFO] rank-5:{:.2f}%"</span>.format(rank5 * <span class="number">100</span>))</span><br><span class="line">db.close()</span><br></pre></td></tr></tbody></table></figure></div><p></p><h2 id="Flowers-17结果"><a href="#Flowers-17结果" class="headerlink" title="Flowers-17结果"></a>Flowers-17结果</h2><p>下面我们使用Flowers-17数据进行实验，运行下面命令:<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line"><span class="meta">$</span> python rank_accuracy.py --db youPath/data/flowers17/hdf5/features.hdf5 -model youPath/flowers17.cpickle</span><br></pre></td></tr></tbody></table></figure></div><p></p><p>将得到如下结果:</p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line">[INFO] loading pre-trained model...</span><br><span class="line">[INFO] predicting....</span><br><span class="line">[INFO] rank-1:90.00%</span><br><span class="line">[INFO] rank-5:99.71%</span><br></pre></td></tr></tbody></table></figure></div><h2 id="CALTECH-101结果"><a href="#CALTECH-101结果" class="headerlink" title="CALTECH-101结果"></a>CALTECH-101结果</h2><p>我们尝试另外一个数据例子—CALTECH-101，运行下面代码：<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line"><span class="meta">$</span> python rank_accuracy.py --db youPath/data/caltech101/hdf5/features.hdf5 --model youPath/caltech101.cpickle</span><br></pre></td></tr></tbody></table></figure></div><p></p><p>得到的结果如下；<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line">[INFO] loading pre-trained model...</span><br><span class="line">[INFO] predicting...</span><br><span class="line">[INFO] rank-1: 95.58%</span><br><span class="line">[INFO] rank-5: 99.45%</span><br></pre></td></tr></tbody></table></figure></div><p></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在本节中，我们讨论了rank-1和rank-5准确度概念。在大型的、具有挑战性的数据集(如ImageNet)上，除了要关注rank-1准确度，还需要关注rank-5准确度，在这些数据集中，即使是人眼查看也无法正确地给每一张图像贴上真实的标签。在这种情况下，如果真实标签存在于top5预测中，那么可以认为我们的模型的预测是“正确的”。</p><p><strong>说明</strong>：rank-1和rank-5准确性并不仅限于深度学习和图像分类，还可以使用在其它领域。</p><p>详细代码位置：<a href="https://github.com/lonePatient/Deep_Learning_For_Computer_Vision_With_Python/tree/master/PB" target="_blank" rel="noopener">github</a></p></div><div><div><div style="text-align:center;color:#ccc;font-size:14px">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div></div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/深度学习/" rel="tag"><i class="fa fa-envira"></i> 深度学习</a> <a href="/tags/计算机视觉/" rel="tag"><i class="fa fa-envira"></i> 计算机视觉</a></div><div class="post-widgets"><div id="needsharebutton-postbottom"><span class="btn"><i class="fa fa-share-alt" aria-hidden="true"></i></span></div></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2018/03/04/evaluate-your-machine-learning-algorithm.html" rel="prev" title="常用的机器学习算法衡量指标"><i class="fa fa-chevron-left"></i> 常用的机器学习算法衡量指标</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/2018/02/27/understand-convolution.html" rel="next" title="对深度可分离卷积、分组卷积、扩张卷积、转置卷积（反卷积）的理解">对深度可分离卷积、分组卷积、扩张卷积、转置卷积（反卷积）的理解 <i class="fa fa-chevron-right"></i></a></div></div></footer></div>
https://lonepatient.top/2018/03/03/Deep_Learning_For_Computer_Vision_With_Python_PB_04.html
