<div class="post-body" itemprop="articleBody"><p>在深度学习实践中，当训练数据量少时，可能会出现过拟合问题。根据Goodfellow等人的观点，我们对学习算法的任何修改的目的都是为了减小泛化误差，而不是训练误差。</p><p>我们已经在sb[后续补充]中提到了不同类型的正则化手段来防止模型的过拟合，然而，这些都是针对参数的正则化形式，往往要求我们修改loss函数。事实上，还有其他方式防止模型过拟合，比如：</p><a id="more"></a><ul><li>1.修改网络本身架构</li><li>2.增加数据</li></ul><p>Dropout是通过修改网络本身结构以达到正则化效果的技术。Dropout是指在深度学习网络的训练过程中，对于神经网络单元，按照一定的概率将其暂时从网络中丢弃。<strong>注意是暂时</strong>，对于随机梯度下降来说，由于是随机丢弃，故而每一个mini-batch都在训练不同的网络。</p><p>在这节，我们讨论另外一种防止过拟合方法，叫做数据增强(data augmentation),该方法主要对训练数据集进行一定的变换，改变图片的外观，然后将得到的‘新’图片进行模型训练。使用数据增强技术可以得到更多的数据。</p><p><strong>备注</strong>：预测时候是不是也可以利用data augmentation，结果使用投票方法得到呢？</p><h2 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h2><p>数据增强主要是运用各种技术生成新的训练样本，比如随机旋转或平移等，虽然，‘新’的样本在一定程度上改变了外观，但是样本的标签保持不变。使用数据增强技术可以增加模型训练的样本数据，一般而言，当模型不断地学习新的数据时，模型的泛化性会得到一定的提高。但是有一点需要注意，大多数情况下，数据增强会降低模型训练的准确度，而会提高模型测试的准确度，因此，我们一般不参考数据增强下的训练数据集的评估结果，而是参考测试集上的评估结果。</p><p><a href="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/85865435.jpg" class="fancybox fancybox.image" rel="group"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/85865435.jpg" alt=""></a></p><center>图2.1：左：随机从正态分布产生250条数据，右：对分布做微小的随机干扰</center><p>图2.1左，我们从标准的正态分布中产生一定量的数据，如果对该数据训练一个模型，可以得到一个很好的结果，但是在实际中，数据是很难严格满足标准的正态分布。相反，为了提高模型的通用性。我们对该分布进行微小的随机干扰，使得数据仍然满足一个近似正态分布，如图2.1右，在此数据训练得到的模型有更好的泛化性。</p><p>在计算机视觉中，使用数据增强是非常合理的，由于图像数据的特殊性，可以通过简单的几何变换从原始图像中获额外的训练数据，而且不改变图像的标签，常见的变换有：</p><ul><li>翻转: 水平翻转或者上下翻转图像</li><li>旋转：将图像在一定角度范围内旋转</li><li>缩放：将图像在一定尺度内放大或者缩小</li><li>裁剪：在原有图像上裁剪出一块</li><li>平移：将图像在一定尺度范围内平移</li><li>颜色变动：对图像的RGB颜色空间进行一些变换</li><li>噪声绕动：给图像加入一些人工生成的噪声</li></ul><h2 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h2><p>最直观的明白数据增强的效果的最佳方法就是可视化，可以很直观地看到图像的外观变化。为了实现这个可视化，我们基于keras构建一个数据增强的python脚本，名为augmentation_demo.py，并写入以下代码:<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line"><span class="comment">#encoding:utf-8</span></span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> img_to_array</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> load_img</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> argparse</span><br></pre></td></tr></tbody></table></figure></div><p></p><p>其中ImageDataGenerator是keras中数据增强类，包含了各种变换方法。</p><p>接下来，我们解析命令行参数：<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line"><span class="comment"># 构造参数解析和解析参数</span></span><br><span class="line">ap = argparse.ArgumentParser()</span><br><span class="line">ap.add_argument(<span class="string">'-i'</span>,<span class="string">'--image'</span>,required=<span class="keyword">True</span>,help = <span class="string">'path to the input image'</span>)</span><br><span class="line">ap.add_argument(<span class="string">'-o'</span>,<span class="string">'--ouput'</span>,required=<span class="keyword">True</span>,help =<span class="string">'path to ouput directory to store augmentation examples'</span>)</span><br><span class="line">ap.add_argument(<span class="string">'-p'</span>,<span class="string">'--prefix'</span>,type=str,default=<span class="string">'image'</span>,help=<span class="string">'output fielname prefix'</span>)</span><br><span class="line">args = vars(ap.parse_args())</span><br></pre></td></tr></tbody></table></figure></div><p></p><p>其中每个参数详细如下:</p><ul><li>—image：需要进行数据增强的原始图像路径</li><li>—output：保存图像的路径</li><li>—prefix：字符串，变换后的图像文件名</li></ul><p>接下来，加载输入图像，将其转换为keras支持的array形式数组，并对图像增加一个额外维度。</p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line"><span class="comment"># 加载图像，并转化为numpy的array</span></span><br><span class="line">print(<span class="string">'[INFO] loading example image...'</span>)</span><br><span class="line">image = load_img(args[<span class="string">'image'</span>])</span><br><span class="line">image = img_to_array(image)</span><br><span class="line"><span class="comment">#增加一个维度</span></span><br><span class="line">image = np.expand_dims(image,axis = <span class="number">0</span>) <span class="comment">#在0位置增加数据，主要是batch size</span></span><br></pre></td></tr></tbody></table></figure></div><p>初始化ImageDataGenerator：</p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line">aug = ImageDataGenerator(</span><br><span class="line">    rotation_range=<span class="number">30</span>,       <span class="comment"># 旋转角度</span></span><br><span class="line">    width_shift_range=<span class="number">0.1</span>,   <span class="comment"># 水平平移幅度</span></span><br><span class="line">    height_shift_range= <span class="number">0.1</span>, <span class="comment"># 上下平移幅度</span></span><br><span class="line">    shear_range=<span class="number">0.2</span>,         <span class="comment"># 逆时针方向的剪切变黄角度</span></span><br><span class="line">    zoom_range=<span class="number">0.2</span>,          <span class="comment"># 随机缩放的角度</span></span><br><span class="line">    horizontal_flip=<span class="keyword">True</span>,    <span class="comment"># 水平翻转</span></span><br><span class="line">    fill_mode=<span class="string">'nearest'</span>      <span class="comment"># 变换超出边界的处理</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 初始化目前为止的图片产生数量</span></span><br><span class="line">total = <span class="number">0</span></span><br></pre></td></tr></tbody></table></figure></div><p>ImageDataGenerator类有很多参数，这里无法一一列举。想了解详细的参数意义，请参阅官方的<a href="https://keras-cn.readthedocs.io/en/latest/" target="_blank" rel="noopener">Keras文档</a>. 相反，我们列出几个最有可能实际中用到的:</p><ul><li>rotation_range：控制随机旋转的角度，这里我们设置为30度</li><li>width_shift_range和height_shift_range:：主要控制水平和垂直移动。</li><li>shear_range：浮点数，剪切强度（逆时针方向的剪切变换角度)</li><li>zoom_range：浮点数或形如[lower,upper]的列表，随机缩放的幅度，若为浮点数，则相当于[lower,upper] = [1 - zoom_range, 1+zoom_range]</li><li>horizontal_flip：是否对图像进行水平翻转，一般而言，大多数图像进行水平翻转是不改变原始的图像标签的，但是一些特殊情况会改变图像的语义信息。</li></ul><p><strong>备注</strong>：无论使用哪种变换方法，需要注意我们想要的是增加数据集，只改变图像表面的外观，而不改变原始的图像语义信息。</p><p>一旦ImageDataGenerato初始化后，我们就可以产生新的训练数据集：</p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line">print(<span class="string">"[INFO] generating images..."</span>)</span><br><span class="line">imageGen = aug.flow(image,batch_size=<span class="number">1</span>,save_to_dir=args[<span class="string">'output'</span>],save_prefix=args[<span class="string">'prefix'</span>],save_format=<span class="string">'jpg'</span>)</span><br><span class="line"><span class="keyword">for</span> image <span class="keyword">in</span> imageGen:</span><br><span class="line">    total += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 只输出10个案例样本</span></span><br><span class="line">    <span class="keyword">if</span> total == <span class="number">10</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></tbody></table></figure></div><p>首先，初始化构造图像数据增强的生成器，并传入参数——输入图像，batch_size设置为1（因为我们这里只增加一个图像），输出的路径等。然后，对imageGen生成器进行遍历，imageGen每次被请求时都会自动生成一个新的训练样本。当新增10张图时，就停止。</p><p>执行下列命令，产生数据增强结果:</p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="BASH"><figure class="iseeu highlight /bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line">$ python augmentation_demo.py --image jemma.png --output output</span><br></pre></td></tr></tbody></table></figure></div><p>当脚本执行完之后，你可以看到：</p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line">ls output/</span><br><span class="line">image_0_1227.jpg image_0_2358.jpg image_0_4205.jpg image_0_4770.jpg ...</span><br></pre></td></tr></tbody></table></figure></div><p><a href="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/48983125.jpg" class="fancybox fancybox.image" rel="group"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/48983125.jpg" alt=""></a></p><center>图2.2,左：输入图像，右：数据增强之后结果</center><p>如图2.2右所示，每张图像都是经过随机旋转、剪切、缩放或水平翻转得到的。对原始图像微小变换之后，可以看到‘新’图像都保留了原始的标签：dog，从而使我们的神经网络在训练时可以学习新的模式。</p><p>数据增强技术虽然有可能降低模型训练时的准确度，但是，数据增强可以一定程度上降低过拟合，确保我们的模型可以更好地推广到新的输入样本。更重要的是，当我们只有少量数据集时——往往是无法进行深度学习实践的，那么可以利用数据增强生成额外的训练数据，从而减少训练深度学习网络需要手工标记的数据。</p><h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>在本节的第一部分中，我们将讨论Flowers-17数据集，这是一个非常小的数据集(对计算机视觉任务的而言)，以及数据增强如何帮助我们生成额外的训练样本。主要做2个实验：</p><ul><li><p>在Flowers-17上训练MiniVGGNet，不使用数据增强。</p></li><li><p>在flower -17上使用数据增强技术训练MIniVGGNet。</p></li></ul><h3 id="Flowers-17-数据集"><a href="#Flowers-17-数据集" class="headerlink" title="Flowers-17 数据集"></a>Flowers-17 数据集</h3><p>Flowers-17数据集是一个细粒度分类数据，我们的任务是识别17种不同的花。图像数据集非常小，每个类只有80张图像，总共1360张图片。在计算机视觉任务中，应用深度学习算法一般要求每个类别差不多有1000 - 5000个数据，因此，Flowers-17数据集是严重不满足。</p><p>我们称Flowers-17为细粒度分类任务，因为所有类别都非常相似(主要花的物种)。事实上，我们可以把这些类别都看作子类别。虽然类别之间是不同的，但是存在相同的结构，比如花瓣，雄蕊、雌蕊等。</p><p><a href="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/86321860.jpg" class="fancybox fancybox.image" rel="group"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/86321860.jpg" alt=""></a></p><p>细粒度分类任务对于深度学习实践者来说是最具挑战性的，因为这意味着我们的机器学习模型需要学习极端的细粒度特征来区分非常相似的各个类。考虑到我们有限的train数据，这种细粒度的分类任务变得更加困难。</p><p>Flowers-17数据可以从<a href="http://www.robots.ox.ac.uk/~vgg/data/flowers/17/index.html" target="_blank" rel="noopener">地址</a> 下载。</p><h3 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h3><p>在此之前，我们处理图像时，一般是将它们调整为固定大小，忽略了纵横比。对于一般的数据集，这样做是可以接受的。但是，对于更具挑战性的数据集，我们将图像大小调整到一个固定的大小时，需要保持长宽比。比如图2.4：</p><p><a href="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/34184085.jpg" class="fancybox fancybox.image" rel="group"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/34184085.jpg" alt=""></a></p><center>图2.4</center><p>左图是输入的原始图像，我们调整图像的大小为256×256(中间)，忽略纵横比，从中间图可以看到图像发生了一定的扭曲。再对比右图，考虑图像的纵横比下，我们首先沿着较短的部分调整大小，比如这里宽度调整为256，然后沿高度裁剪图像，使其高度为256。虽然我们在剪辑过程中丢弃了部分图像，但我们也保留了部分图像原始长宽比。保持一致的纵横比可以使卷积神经网络学习到更有辨别力，一致性的特征。这是我们处理更高级的数据集比如ImageNet用到的一种常见的技术。</p><p>为了了解预处理，让我们对pyimagesearch项目结构增加一个AspectAwarePreprocessor类:<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line">--- pyimagesearch</span><br><span class="line">|    |--- __init__.py</span><br><span class="line">|    |--- callbacks</span><br><span class="line">|    |--- nn</span><br><span class="line">|    |--- preprocessing</span><br><span class="line">|        |--- __init__.py</span><br><span class="line">|        |--- aspectawarepreprocessor.py</span><br><span class="line">|        |--- imagetoarraypreprocessor.py</span><br><span class="line">|        |--- simplepreprocessor.py</span><br><span class="line">|    |--- utils</span><br></pre></td></tr></tbody></table></figure></div><p></p><p>在preprocessing子模块下，新建一个文件，名为aspectawarepreprocessor.py，并写入以下代码；<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line"><span class="comment">#encoding:utf-8</span></span><br><span class="line"><span class="comment"># 加载所需要模块</span></span><br><span class="line"><span class="keyword">import</span> cv2     <span class="comment">#安装：pip install opencv-python</span></span><br><span class="line"><span class="keyword">import</span> imutils <span class="comment"># 安装：pip install imutils</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AspectAwarePreprocessor</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,width,height,inter = cv2.INTER_AREA)</span>:</span></span><br><span class="line">        <span class="comment"># 定义所需要的变量</span></span><br><span class="line">        self.width = width</span><br><span class="line">        self.heigth = height</span><br><span class="line">        self.inter = inter</span><br></pre></td></tr></tbody></table></figure></div><p></p><p>就像在SimplePreprocessor中一样，函数需要两个参数(目标输出图像的宽度和高度)以及调整图像所使用的插值方法。定义预处理函数如下:<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span><span class="params">(self,image)</span>:</span></span><br><span class="line">	<span class="comment"># 获取image的维度</span></span><br><span class="line">    (h,w) = image.shape[:<span class="number">2</span>]</span><br><span class="line">    <span class="comment"># 修剪时用到的增量</span></span><br><span class="line">    dw = <span class="number">0</span></span><br><span class="line">    dh = <span class="number">0</span></span><br></pre></td></tr></tbody></table></figure></div><p></p><p>预处理函数传入的是需要处理的图像。预处理主要包含两步：</p><ul><li>1.确定最短的维度并沿着它调整大小</li><li>2.沿最大维度裁剪图像，以获得目标的宽度和高度</li></ul><p>代码如下：<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line"><span class="keyword">if</span> w &lt; h:</span><br><span class="line">    image = imutils.resize(image,width = self.width, inter = self.inter)</span><br><span class="line">    dh = int((image.shape[<span class="number">0</span>] - self.height) / <span class="number">2.0</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    image = imutils.resize(image, height=self.height, inter=self.inter)</span><br><span class="line">    dw = int((image.shape[<span class="number">1</span>] - self.width) / <span class="number">2.0</span>)</span><br></pre></td></tr></tbody></table></figure></div><p></p><p>我们需要重新抓取宽度和高度，并使用delta裁剪图像的中心:<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line">(h,w) = image.shape[:<span class="number">2</span>]</span><br><span class="line">image = image[dh:h - dh,dw:w-dw]</span><br><span class="line"><span class="keyword">return</span> cv2.resize(image,(self.width,self.height), interpolation=self.inter)</span><br></pre></td></tr></tbody></table></figure></div><p></p><p>在裁剪过程中(由于舍入误差),目标图像尺寸可能增加或者减小一个像素，因此，我们调用cv2模块调整大小以确保我们的输出图像满足一定的宽度和高度。然后将预处理后的图像返回给调用函数。</p><p>数据预处理完之后，接下来主要构建模型以及对模型进行训练和评估。</p><h3 id="Flowers-17：不使用数据增强"><a href="#Flowers-17：不使用数据增强" class="headerlink" title="Flowers-17：不使用数据增强"></a>Flowers-17：不使用数据增强</h3><p>首先，我们不对Flower-17数据进行数据增强，直接对原始数据训练MiniVGGNe模型，新建一个脚本文件，名为minivggnet_flowers17.py，并写入以下代码：</p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line"><span class="comment">#encoding:utf-8</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelBinarizer</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="keyword">from</span> pyimagesearch.preprocessing <span class="keyword">import</span> ImageToArrayPreprocessor <span class="keyword">as</span> IAP</span><br><span class="line"><span class="keyword">from</span> pyimagesearch.preprocessing <span class="keyword">import</span> AspectAwarePreprocessor <span class="keyword">as</span> AAP</span><br><span class="line"><span class="keyword">from</span> pyimagesearch.preprocessing <span class="keyword">import</span> ImageMove <span class="keyword">as</span> IM <span class="comment">#新增模块</span></span><br><span class="line"><span class="keyword">from</span> pyimagesearch.datasets <span class="keyword">import</span> SimpleDatasetLoader <span class="keyword">as</span> SDL</span><br><span class="line"><span class="keyword">from</span> pyimagesearch.nn.conv <span class="keyword">import</span> MiniVGGNet <span class="keyword">as</span> MVN</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> SGD</span><br><span class="line"><span class="keyword">from</span> imutils <span class="keyword">import</span> paths</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> os</span><br></pre></td></tr></tbody></table></figure></div><p><strong>说明</strong>： 由于从官方下载的Flower-17数据是没有标签的，因此，我增加了一个模块ImageMove，主要是将图片进行分类，对应到每一个标签文件夹中，并使用0-16代表类别。</p><p>定义命令行参数，这里只需要传入图片的数据路径<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line">ap = argparse.ArgumentParser()</span><br><span class="line">ap.add_argument(<span class="string">"-d"</span>, <span class="string">"--dataset"</span>, required=<span class="keyword">True</span>,help=<span class="string">"path to input dataset"</span>)args = vars(ap.parse_args())</span><br></pre></td></tr></tbody></table></figure></div><p></p><p>这里新增一个分类图片模块，使用0-16代表不同的类别<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line">print(<span class="string">'[INFO] moving image to label folder.....'</span>)</span><br><span class="line">im  = IM.MoveImageToLabel(dataPath=args[<span class="string">'dataset'</span>])</span><br><span class="line">im.makeFolder()</span><br><span class="line">im.move()</span><br></pre></td></tr></tbody></table></figure></div><p></p><p>数据目录结构:<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line">原始目录</span><br><span class="line">flowers17/jpg/{image}</span><br><span class="line">处理完之后的目录</span><br><span class="line">flowers17/{species}/{image}</span><br><span class="line">flowers17/3/image_0241.jpg</span><br></pre></td></tr></tbody></table></figure></div><p></p><p>处理完图片目录，接下来从数据中提取数据标签<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line">print(<span class="string">"[INFO] loading images..."</span>)</span><br><span class="line">imagePaths = list(paths.list_images(args[<span class="string">"dataset"</span>]))</span><br><span class="line">classNames = [pt.split(os.path.sep)[<span class="number">-2</span>] <span class="keyword">for</span> pt <span class="keyword">in</span> imagePaths]</span><br><span class="line">classNames = [str(x) <span class="keyword">for</span> x <span class="keyword">in</span> np.unique(classNames)]</span><br></pre></td></tr></tbody></table></figure></div><p></p><p>加载数据集，并对数据进行标准化处理<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line"><span class="comment"># 预处理模块</span></span><br><span class="line">aap = AspectAwarePreprocessor(<span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">iap = ImageToArrayPreprocessor()</span><br><span class="line">sdl = SimpleDatasetLoader(preprocessors=[aap, iap])</span><br><span class="line">(data, labels) = sdl.load(imagePaths, verbose=<span class="number">500</span>)</span><br><span class="line"><span class="comment"># 标准化</span></span><br><span class="line">data = data.astype(<span class="string">"float"</span>) / <span class="number">255.0</span></span><br></pre></td></tr></tbody></table></figure></div><p></p><p>将数据集分成train数据和test数据，并对标签one-hot编码化<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line">(trainX, testX, trainY, testY) = train_test_split(data, labels,test_size=<span class="number">0.25</span>, random_state=<span class="number">42</span>)</span><br><span class="line">trainY = LabelBinarizer().fit_transform(trainY)</span><br><span class="line">testY = LabelBinarizer().fit_transform(testY)</span><br></pre></td></tr></tbody></table></figure></div><p></p><p>初始化模型，并进行训练<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line"><span class="comment"># 初始化模型和优化器</span></span><br><span class="line">print(<span class="string">"[INFO] compiling model..."</span>)</span><br><span class="line">opt = SGD(lr=<span class="number">0.05</span>)</span><br><span class="line">model = MiniVGGNet.build(width=<span class="number">64</span>, height=<span class="number">64</span>, depth=<span class="number">3</span>,</span><br><span class="line">classes=len(classNames))</span><br><span class="line">model.compile(loss=<span class="string">"categorical_crossentropy"</span>, optimizer=opt,</span><br><span class="line">metrics=[<span class="string">"accuracy"</span>])</span><br><span class="line"><span class="comment"># 训练网络</span></span><br><span class="line">print(<span class="string">"[INFO] training network..."</span>)</span><br><span class="line">H = model.fit(trainX, trainY, validation_data=(testX, testY),</span><br><span class="line">batch_size=<span class="number">32</span>, epochs=<span class="number">100</span>, verbose=<span class="number">1</span>)</span><br></pre></td></tr></tbody></table></figure></div><p></p><p>在数据预处理部分，我们将图片大小调整为64x64，因此，MiniVGGNet网络主要输入shape为64x64x3(像素宽，像素高，通道数)的数据，类别个数是len(classNames)，在本例中，它等于17。</p><p>使用SGD对模型进行训练，训练次数为100次，并对训练过程进行可视化。<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line"><span class="comment"># 评估模型性能</span></span><br><span class="line">print(<span class="string">"[INFO] evaluating network..."</span>)</span><br><span class="line">predictions = model.predict(testX, batch_size=<span class="number">32</span>)</span><br><span class="line">print(classification_report(testY.argmax(axis=<span class="number">1</span>),</span><br><span class="line">predictions.argmax(axis=<span class="number">1</span>), target_names=classNames))</span><br><span class="line"><span class="comment"># loss和精度可视化</span></span><br><span class="line">plt.style.use(<span class="string">"ggplot"</span>)</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(np.arange(<span class="number">0</span>, <span class="number">100</span>), H.history[<span class="string">"loss"</span>], label=<span class="string">"train_loss"</span>)</span><br><span class="line">plt.plot(np.arange(<span class="number">0</span>, <span class="number">100</span>), H.history[<span class="string">"val_loss"</span>], label=<span class="string">"val_loss"</span>)</span><br><span class="line">plt.plot(np.arange(<span class="number">0</span>, <span class="number">100</span>), H.history[<span class="string">"acc"</span>], label=<span class="string">"train_acc"</span>)</span><br><span class="line">plt.plot(np.arange(<span class="number">0</span>, <span class="number">100</span>), H.history[<span class="string">"val_acc"</span>], label=<span class="string">"val_acc"</span>)</span><br><span class="line">plt.title(<span class="string">"Training Loss and Accuracy"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Epoch #"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Loss/Accuracy"</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure></div><p></p><p>完成上述代码之后，执行下面命令，将得到MiniVGGNet模型训练的结果<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line"><span class="meta">$</span><span class="bash"> python minivggnet_flowers17.py --dataset yourpath/flowers17</span></span><br></pre></td></tr></tbody></table></figure></div><p></p><p>结果如下<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line">             precision    recall  f1-score   support</span><br><span class="line">          0       0.36      0.50      0.42        16</span><br><span class="line">          1       0.52      0.57      0.55        21</span><br><span class="line">         10       0.83      0.62      0.71        16</span><br><span class="line">         11       0.60      0.43      0.50        21</span><br><span class="line">         12       0.62      0.69      0.65        26</span><br><span class="line">         13       0.53      0.39      0.45        23</span><br><span class="line">         14       0.74      0.58      0.65        24</span><br><span class="line">         15       0.70      0.73      0.71        22</span><br><span class="line">         16       0.82      0.82      0.82        17</span><br><span class="line">          2       0.62      0.71      0.67        14</span><br><span class="line">          3       0.79      0.65      0.71        23</span><br><span class="line">          4       0.44      0.50      0.47        22</span><br><span class="line">          5       0.76      0.64      0.70        25</span><br><span class="line">          6       0.78      0.74      0.76        19</span><br><span class="line">          7       0.26      0.36      0.30        14</span><br><span class="line">          8       0.58      0.71      0.64        21</span><br><span class="line">          9       0.79      0.94      0.86        16</span><br><span class="line">avg / total       0.64      0.62      0.62       340</span><br></pre></td></tr></tbody></table></figure></div><p></p><p><a href="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/1843980.jpg" class="fancybox fancybox.image" rel="group"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/1843980.jpg" alt=""></a></p><center>图2.5</center><p>从输出结果中可以看出，模型的准确率为64%，由于有限的数据集，该结果还可以接受的。但是从图2.5中，我们可以看出模型出现了过拟合现象，训练不到20次，训练loss已经变得相当小。主要原因是数据量太少了，训练数据集只有1020个样本且每个类别只有60个样本。</p><p>此外，从图2.5中可以看到训练精度在不到20次的迭代中已经超过了95%，在最后一次迭代中获得了100%的准确性——很明显地发生了过拟合。由于缺乏大量的训练数据，MiniVGGNet对训练数据的样本学到了过于细微的特征，无法推广到测试数据。为了避免过拟合，我们可以应用正则化技术——在本章的上下文中，我们的正则化方法主要是数据增强。在实践中，您还将包括其他形式的正则化(权值衰减、Dropout等)，以进一步减少过拟合的影响。</p><h3 id="Flowers-17-Data-Augmentation"><a href="#Flowers-17-Data-Augmentation" class="headerlink" title="Flowers-17: Data Augmentation"></a>Flowers-17: Data Augmentation</h3><p>这一部分，我们将与上节相同的训练过程，唯一不同的是对原始数据进行了数据增强。新建一个脚本，名为minivggnet_flowers17_data_aug.py，并写入以下代码：<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line"><span class="comment">#encoding:utf-8</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelBinarizer</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="keyword">from</span> pyimagesearch.preprocessing <span class="keyword">import</span> ImageToArrayPreprocessor <span class="keyword">as</span> IAP</span><br><span class="line"><span class="keyword">from</span> pyimagesearch.preprocessing <span class="keyword">import</span> AspectAwarePreprocessor <span class="keyword">as</span> AAP</span><br><span class="line"><span class="keyword">from</span> pyimagesearch.preprocessing <span class="keyword">import</span> ImageMove <span class="keyword">as</span> IM</span><br><span class="line"><span class="keyword">from</span> pyimagesearch.datasets <span class="keyword">import</span> SimpleDatasetLoader <span class="keyword">as</span> SDL</span><br><span class="line"><span class="keyword">from</span> pyimagesearch.nn.conv <span class="keyword">import</span> MiniVGGNet <span class="keyword">as</span> MVN</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator <span class="comment"># 数据增强类</span></span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> SGD</span><br><span class="line"><span class="keyword">from</span> imutils <span class="keyword">import</span> paths</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> os</span><br></pre></td></tr></tbody></table></figure></div><p></p><p>与minivggnet_flowers17.py一样，不同的是第10行新增了数据增强模块。</p><p>接下来同样进行数据预处理<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code" copyflag="1"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line">ap  = argparse.ArgumentParser()</span><br><span class="line">ap.add_argument(<span class="string">'-d'</span>,<span class="string">'--dataset'</span>,required=<span class="keyword">True</span>,help=<span class="string">'path to input dataset'</span>)</span><br><span class="line">args = vars(ap.parse_args())</span><br><span class="line">print(<span class="string">'[INFO] moving image to label folder.....'</span>)</span><br><span class="line">im  = IM.MoveImageToLabel(dataPath=args[<span class="string">'dataset'</span>])</span><br><span class="line">im.makeFolder()</span><br><span class="line">im.move()</span><br><span class="line">print(<span class="string">"[INFO] loading images..."</span>)</span><br><span class="line">imagePaths = [ x <span class="keyword">for</span> x <span class="keyword">in</span> list(paths.list_images(args[<span class="string">'dataset'</span>])) <span class="keyword">if</span> x.split(os.path.sep)[<span class="number">-2</span>] !=<span class="string">'jpg'</span>]</span><br><span class="line">classNames = [pt.split(os.path.sep)[<span class="number">-2</span>] <span class="keyword">for</span> pt <span class="keyword">in</span> imagePaths ]</span><br><span class="line">classNames = [str(x) <span class="keyword">for</span> x <span class="keyword">in</span> np.unique(classNames)]</span><br><span class="line">aap = AAP.AspectAwarePreprocesser(<span class="number">64</span>,<span class="number">64</span>)</span><br><span class="line">iap = IAP.ImageToArrayPreprocess()</span><br><span class="line">sdl = SDL.SimpleDatasetLoader(preprocessors = [aap,iap])</span><br><span class="line">(data,labels) = sdl.load(imagePaths,verbose = <span class="number">500</span>)</span><br><span class="line">data = data.astype(<span class="string">'float'</span>) / <span class="number">255.0</span></span><br><span class="line">(trainX,testX,trainY,testY) = train_test_split(data,labels,test_size=<span class="number">0.25</span>,random_state  =<span class="number">43</span>)</span><br><span class="line">trainY = LabelBinarizer().fit_transform(trainY)</span><br><span class="line">testY = LabelBinarizer().fit_transform(testY)</span><br></pre></td></tr></tbody></table></figure></div><p></p><p>数据预处理完之后，在模型训练之前，我们对train数据进行数据增强处理。<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line">aug = ImageDataGenerator(rotation_range=<span class="number">30</span>, width_shift_range=<span class="number">0.1</span>,height_shift_range=<span class="number">0.1</span>, shear_range=<span class="number">0.2</span>, zoom_range=<span class="number">0.2</span>,horizontal_flip=<span class="keyword">True</span>, fill_mode=<span class="string">"nearest"</span>)</span><br></pre></td></tr></tbody></table></figure></div><p></p><p>主要的变换有：</p><ul><li>随机旋转+-30度</li><li>水平和垂直平移0.2</li><li>裁剪0.2</li><li>缩放0.2</li><li>水平翻转</li></ul><p>通常而言，这些调整的参数值需要根据你的具体数据进行设置，一般而言，旋转幅度控制在[0，30]之间，水平和垂直平移控制在[0.1，0.2]（缩放也是一样的)，如果水平翻转没有改变图片的语义信息，标签没有发生变化，则应该也使用水平翻转。</p><p>接下来。对模型进行初始化<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line">print(<span class="string">"[INFO] compiling model..."</span>)</span><br><span class="line">opt = SGD(lr=<span class="number">0.05</span>)</span><br><span class="line">model = MVN.MiniVGGNet.build(width=<span class="number">64</span>, height=<span class="number">64</span>, depth=<span class="number">3</span>,classes=len(classNames))</span><br><span class="line">model.compile(loss=<span class="string">"categorical_crossentropy"</span>, optimizer=opt,metrics=[<span class="string">"accuracy"</span>])</span><br></pre></td></tr></tbody></table></figure></div><p></p><p>由于我们使用了数据增强处理，因此，训练模型部分，需要简单进行调整<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">print(<span class="string">"[INFO] training network..."</span>)</span><br><span class="line"><span class="comment"># 这里使用fit_generator</span></span><br><span class="line">H = model.fit_generator(aug.flow(trainX, trainY, batch_size=<span class="number">32</span>),validation_data=(testX, testY), steps_per_epoch=len(trainX) // <span class="number">32</span>,epochs=<span class="number">100</span>, verbose=<span class="number">1</span>)</span><br></pre></td></tr></tbody></table></figure></div><p></p><p>需要注意的是，这里使用的是.fit_generator而不是.fit，第一个参数为aug.flow，生成经过数据增强或标准化后的batch数据。flow输入的是对应的训练数据和标签。</p><p>steps_per_epoch的含义是一个epoch分成多少个batch_size， 每个epoch以经过模型的样本数达到samples_per_epoch时，记一个epoch结束。如果说训练样本树N=1000，steps_per_epoch = 10，那么相当于一个batch_size=100。</p><p>接下来，开始训练模型，并对结果进行可视化。<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line"><span class="comment"># 评估网络</span></span><br><span class="line">print(<span class="string">"[INFO] evaluating network..."</span>)</span><br><span class="line">predictions = model.predict(testX, batch_size=<span class="number">32</span>)</span><br><span class="line">print(classification_report(testY.argmax(axis=<span class="number">1</span>),</span><br><span class="line">predictions.argmax(axis=<span class="number">1</span>), target_names=classNames))</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss和精度可视化</span></span><br><span class="line">plt.style.use(<span class="string">"ggplot"</span>)</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(np.arange(<span class="number">0</span>, <span class="number">100</span>), H.history[<span class="string">"loss"</span>], label=<span class="string">"train_loss"</span>)</span><br><span class="line">plt.plot(np.arange(<span class="number">0</span>, <span class="number">100</span>), H.history[<span class="string">"val_loss"</span>], label=<span class="string">"val_loss"</span>)</span><br><span class="line">plt.plot(np.arange(<span class="number">0</span>, <span class="number">100</span>), H.history[<span class="string">"acc"</span>], label=<span class="string">"train_acc"</span>)</span><br><span class="line">plt.plot(np.arange(<span class="number">0</span>, <span class="number">100</span>), H.history[<span class="string">"val_acc"</span>], label=<span class="string">"val_acc"</span>)</span><br><span class="line">plt.title(<span class="string">"Training Loss and Accuracy"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Epoch #"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Loss/Accuracy"</span>)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></tbody></table></figure></div><p></p><p><strong>注意</strong>:上面我们只对train数据进行增强处理，而对于test数据不做任何处理。</p><p>完成上述代码之后，执行下面命令，得到结果<br></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line"><span class="meta">$</span><span class="bash"> python minivggnet_flowers17_data_aug.py --dataset yourpath/flowers17</span></span><br></pre></td></tr></tbody></table></figure></div><p></p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><button class="btn-copy" data-clipboard-snippet="">  <i class="fa fa-clipboard"></i><span>copy</span></button><pre><span class="line">             precision    recall  f1-score   support</span><br><span class="line">          0       0.64      0.56      0.60        16</span><br><span class="line">          1       0.59      0.76      0.67        21</span><br><span class="line">         10       1.00      0.81      0.90        16</span><br><span class="line">         11       0.80      0.57      0.67        21</span><br><span class="line">         12       0.76      0.62      0.68        26</span><br><span class="line">         13       0.52      0.61      0.56        23</span><br><span class="line">         14       0.90      0.75      0.82        24</span><br><span class="line">         15       0.90      0.86      0.88        22</span><br><span class="line">         16       0.93      0.76      0.84        17</span><br><span class="line">          2       0.79      0.79      0.79        14</span><br><span class="line">          3       0.72      0.78      0.75        23</span><br><span class="line">          4       0.67      0.82      0.73        22</span><br><span class="line">          5       0.95      0.76      0.84        25</span><br><span class="line">          6       0.61      0.89      0.72        19</span><br><span class="line">          7       0.33      0.36      0.34        14</span><br><span class="line">          8       0.74      0.81      0.77        21</span><br><span class="line">          9       0.94      0.94      0.94        16</span><br><span class="line">avg / total       0.76      0.74      0.74       340</span><br></pre></td></tr></tbody></table></figure></div><p><a href="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/15866299.jpg" class="fancybox fancybox.image" rel="group"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/15866299.jpg" alt=""></a></p><center>图2.6</center><p>从结果中，我们可以看到，模型准确率从64%提高到76%，比上次提高了12%左右。相比准确率的提高，我们关心的是数据增强是否有助于防止过拟合。从图2.6中，虽然仍然存在过拟合现象，但是相比上次，很明显的发现使用数据增强后，降低了过拟合。首先这两个实验是相同的——我们所做的唯一改变是是否应用了数据增强。两次结果对比，可以看到数据增强可以一定程度上降低过拟合。尽管降低了训练的准确率，但是提高了测试集的准确率，从而提高模型的泛化性。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>数据增强主要对训练数据进行操作的一种正则化技术。顾名思义，数据增强通过应用一系列方法随机地改变训练数据，比如平移，旋转，剪切和翻转等。数据增强的详细变换幅度需要根据具体的应用数据而设计，只要注意一点：应用这些简单的转换不能改变输入图像的标签。每个通过增强得到的图像都可以被认为是一个“新”图像。这样我们可以不断的给模型提供新的训练样本，使模型能够学习到更加具有辨别力，更具泛化性的特征。</p><p>从上述的实验结果表明，应用数据增强技术可以提高模型的准确率，同时有助于减轻过拟合。此外，数据增强也可以增加数据量，降低深度学习需要的人工标记的大量数据集。尽管收集“自然”的训练样本越多越好，但是在无法增加真实的训练样本时，数据增强可以用来克服小数据集的局限性。</p><p>详细代码：<a href="https://github.com/lonePatient/Deep_Learning_For_Computer_Vision_With_Python/tree/master/PB/chapter_02" target="_blank" rel="noopener">github</a></p></div>
https://lonepatient.top/
